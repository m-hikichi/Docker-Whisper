# Whisperの取扱説明書

## 概要
Whisperとは、OpenAIが開発した多様な音声データに対応できる汎用的な音声認識モデルです。Whisperは、複数の言語に対応した音声認識、音声翻訳、言語識別などのタスクを同時に行うことができるマルチタスクモデルでもあります。

## コマンドの使用方法
Whisperを利用するには、whisperというコマンドを使って音声ファイルを入力として与えます。whisperコマンドには、さまざまなオプションが用意されており、モデルの選択や出力の設定などをカスタマイズすることができます。

### コマンドの例
```
whisper --model large --language ja --task transcribe --output_dir ./output input.wav
```
このコマンドでは、largeというモデルを使用し、日本語の音声ファイルinput.wavを入力として与えています。また、--taskオプションにtranscribeを指定しているため、音声を同じ言語のテキストに変換します。最後に、--output_dirオプションで指定した./outputディレクトリに出力が保存されます。

## 主なオプション
- **--model**: 使用するWhisperのモデル名を指定します。デフォルトではsmallというモデルが使われますが、tinyやmedium、largeといった他のモデルも選択できます。モデルのサイズが大きいほど精度が高くなりますが、推論にかかる時間やメモリも増えます。
- **--language**: 音声で話される言語を指定します。Whisperは多言語に対応しており、日本語や英語だけでなく、アラビア語や中国語などの言語も認識できます。言語を指定しない場合は、Whisperが自動的に言語を検出します。
- **--task**: 音声処理のタスクを指定します。transcribeというオプションを選ぶと、音声を同じ言語のテキストに変換します。translateというオプションを選ぶと、音声を英語のテキストに翻訳します。
- **--output_dir**: 出力を保存するディレクトリを指定します。デフォルトではカレントディレクトリに出力されますが、任意のパスを指定できます。
- **--verbose**: 進捗状況やデバッグメッセージを出力するかどうかを指定します。デフォルトではTrueとなっており、標準出力に情報が表示されます。Falseにすると、情報が表示されません。

以上がwhisperコマンドの主なオプションです。他にも細かい設定を変更できるオプションがありますが、詳細は公式ドキュメント を参照してください。
