version: '3'

services:
  openai_whisper_server:
    build:
      context: ../Dockerfile_openai_whisper
      dockerfile: Dockerfile
    image: openai_whisper:20231117
    container_name: openai_whisper_server
    volumes:
      - ../src/utils:/app/src/utils
      - ../src/openai_whisper_server:/app/src/openai_whisper_server
      - ../logging.conf:/app/logging.conf
    working_dir: /app
    ports:
      - "7870:5000"
    environment:
      PYTHONPATH: /app/src/
    tty: true
    entrypoint: sh -c "cd /app/src/openai_whisper_server && uvicorn main:app --host 0.0.0.0 --reload --port 5000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  faster_whisper_server:
    build:
      context: ../Dockerfile_faster_whisper
      dockerfile: Dockerfile
    image: faster_whisper:0.10.0
    container_name: faster_whisper_server
    volumes:
      - ../src/utils:/app/src/utils
      - ../src/faster_whisper_server:/app/src/faster_whisper_server
      - ../logging.conf:/app/logging.conf
    working_dir: /app
    ports:
      - "7871:7860"
    environment:
      PYTHONPATH: /app/src/
    tty: true
    entrypoint: sh -c "python3 /app/src/faster_whisper_server/gradio_app.py --server_name 0.0.0.0 &\
      cd /app/src/faster_whisper_server/ && uvicorn api:app --host 0.0.0.0 --reload --port 5000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  whisper_test_client:
    image: python:3.10
    container_name: whisper_test_client
    volumes:
      - ../test:/app/test
      - ../pytest.ini:/app/pytest.ini
    working_dir: /app
    tty: true
